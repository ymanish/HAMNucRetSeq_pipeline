#!/bin/bash
# ----------------SLURM Parameters---------------- 
#SBATCH -p all.q 
#SBATCH --ntasks 32 # Total of independent tasks or cores
#SBATCH --mem-per-cpu=1G 
#SBATCH --cpus-per-task=1 # Each task gets 2 CPUs (logical cores or threads)
#SBATCH -N 1 
#SBATCH --mail-type=ALL 
#SBATCH -J HAMNucRetSeq_pipeline
#SBATCH -D /home/pol_schiessel/maya620d/HAMNucRetSeq_pipeline
#SBATCH --output=/home/pol_schiessel/maya620d/HAMNucRetSeq_pipeline/log/Array_eukaryote.%A_%a.out 
#SBATCH --error=/home/pol_schiessel/maya620d/HAMNucRetSeq_pipeline/log/Array_eukaryote.%A_%a.error 
#SBATCH -A undefined 

# ----------------Load Modules-------------------- 
module load apps/singularity 

# ----------------Commands------------------------ 
echo $PWD

CHUNK_DIR="/group/pol_schiessel/Manish/HAMNucRetSeq_pipeline/data/bound_regions/chunks"  # Directory with chunk files
OUTPUT_DIR="/group/pol_schiessel/Manish/HAMNucRetSeq_pipeline/output/bound_regions"  # Output directory for results
PATTERN="pooled_peaks_bound.part_"        # Filename pattern before the number
OUTPUT_PATTERN="pooled_peaks_bound_nucfe_"  # Output filename pattern
PYTHON_WORKERS_BATCH_SIZE=1000  # Number of sequences to process in each batch

if [ ! -d "$CHUNK_DIR" ]; then
    echo "ERROR: Chunk directory $CHUNK_DIR does not exist!"
    exit 1
fi
mkdir -p "$OUTPUT_DIR" 


# Automatically determine number of chunks
# Uncomment below and remove the --array=1-<N> above if you prefer automatic counting
CHUNK_FILES=(${CHUNK_DIR}/${PATTERN}*.fa)
TOTAL_CHUNKS=${#CHUNK_FILES[@]}
if [ -z "$SLURM_ARRAY_TASK_COUNT" ]; then
    echo "Array count not set, using detected chunk count: $TOTAL_CHUNKS"
    SLURM_ARRAY_TASK_ID=$((SLURM_ARRAY_TASK_ID % TOTAL_CHUNKS + 1))
fi

# Calculate zero-padded index (3 digits)
TASK_ID_PADDED=$(printf "%03d" $SLURM_ARRAY_TASK_ID)

# Build input filename
INPUT_FILE="${CHUNK_DIR}/${PATTERN}${TASK_ID_PADDED}.fa"

echo "Processing array job $SLURM_ARRAY_TASK_ID"
echo "Using input file: $INPUT_FILE"

# Check if input file exists
if [ ! -f "$INPUT_FILE" ]; then
    echo "ERROR: Input file $INPUT_FILE not found!"
    exit 1
fi

singularity exec --bind $PWD:/project hamnucret.sif python3 /project/src/core/compute_nucfe.py \
    --infile "$INPUT_FILE" \
    --outfile "${OUTPUT_DIR}/${OUT_PATTERN}${TASK_ID_PADDED}.tsv" \
    --n_workers "$SLURM_NTASKS" \
    --batch_size $PYTHON_WORKERS_BATCH_SIZE 

# singularity exec nuc_retention.sif which python3

echo "Free energy calculation done"
