#!/bin/bash
# ---------------- SLURM parameters ----------------
#SBATCH -p all.q
#SBATCH --ntasks 10                 # total logical cores you requested
#SBATCH --mem-per-cpu=1G
#SBATCH --cpus-per-task=1
#SBATCH --cpu-freq=high
#SBATCH --tmp=10G
#SBATCH -N 1
#SBATCH --mail-type=ALL
#SBATCH -J HAMNucRetSeq_pipeline
#SBATCH -D /home/pol_schiessel/maya620d/HAMNucRetSeq_pipeline
#SBATCH --output=/home/pol_schiessel/maya620d/HAMNucRetSeq_pipeline/log/Array_eukaryote.%A_%a.out
#SBATCH --error=/home/pol_schiessel/maya620d/HAMNucRetSeq_pipeline/log/Array_eukaryote.%A_%a.error
#SBATCH -A undefined

# ---------------- Load modules --------------------
module load apps/singularity

# ---------------- Runtime setup -------------------
echo "SLURM job $SLURM_JOB_ID - array task $SLURM_ARRAY_TASK_ID"
echo "Running on $(hostname -s)   ($(lscpu | grep 'Model name' | sed 's/^.*: //'))"

export TMPDIR=/tmp/${USER}_${SLURM_JOB_ID}
mkdir -p "$TMPDIR"

echo "Using TMPDIR=$TMPDIR"



# ------- create a writeable Numba cache unique to this node ----------
NUMBA_CACHE_DIR="$TMPDIR/numba_cache"
mkdir -p "$NUMBA_CACHE_DIR"
export NUMBA_CACHE_DIR
export NUMBA_CPU_NAME=generic      

# Prevent nested parallelism
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export NUMBA_NUM_THREADS=1

# ----------------PARAMETERS------------------------
# PYTHON_WORKERS_BATCH_SIZE=10000 
PYTHON_WORKERS_BATCH_SIZE=100

FLUSH_EVERY=10000
#PYTHON_WORKERS_BATCH_SIZE=2
DNA_METHOD="md"
FDNA="None"
#-----------------DIRECTORIES-------------------------------

# ENERGY_CHUNK_DIR="/group/pol_schiessel/Manish/HAMNucRetSeq_pipeline/output/minpoint_boundpromoter_regions_breath/crystal_freedna_${FDNA}"  # Directory with chunk files
ENERGY_CHUNK_DIR="/group/pol_schiessel/Manish/HAMNucRetSeq_pipeline/output/exactpoint_boundpromoter_regions_breath/crystal_freedna_${FDNA}"  # Directory with chunk files

if [ ! -d "$ENERGY_CHUNK_DIR" ]; then
    echo "ERROR: Chunk directory $ENERGY_CHUNK_DIR does not exist! It is required to run this job."
    exit 1
fi

# OUTPUT_DIR="/group/pol_schiessel/Manish/HAMNucRetSeq_pipeline/output/minpoint_boundpromoter_regions_breath/freedna_${DNA_METHOD}"  # Output directory for results
OUTPUT_DIR="/group/pol_schiessel/Manish/HAMNucRetSeq_pipeline/output/exactpoint_boundpromoter_regions_breath/freedna_${DNA_METHOD}"  # Output directory for results

mkdir -p "$OUTPUT_DIR" 


#-----------------SLURM ARRAY JOB SETUP--------------------
# Automatically determine number of chunks
# Uncomment below and remove the --array=1-<N> above if you prefer automatic counting
CHUNK_FILES=(${ENERGY_CHUNK_DIR}/*.tsv)
TOTAL_CHUNKS=${#CHUNK_FILES[@]}
if [ -z "$SLURM_ARRAY_TASK_COUNT" ]; then
    echo "Array count not set, using detected chunk count: $TOTAL_CHUNKS"
    SLURM_ARRAY_TASK_ID=$((SLURM_ARRAY_TASK_ID % TOTAL_CHUNKS + 1))
fi


# Calculate zero-padded index (3 digits)
TASK_ID_PADDED=$(printf "%03d" $SLURM_ARRAY_TASK_ID)


#### KEEP ONLY UNIQUE ENTRIES ####
mkdir -p ${ENERGY_CHUNK_DIR}/unique
awk -F'\t' -v OFS='\t' 'NR==1 {print $1, $2, $3; next} !seen[$1$2]++ {print $1, $2, $3}' ${ENERGY_CHUNK_DIR}/${TASK_ID_PADDED}.tsv > ${ENERGY_CHUNK_DIR}/unique/${TASK_ID_PADDED}.tsv

# Build input filename
INPUT_FILE="${ENERGY_CHUNK_DIR}/unique/${TASK_ID_PADDED}.tsv"

echo "Processing array job $SLURM_ARRAY_TASK_ID"
echo "Using input file: $INPUT_FILE"

# Check if input file exists
if [ ! -f "$INPUT_FILE" ]; then
    echo "ERROR: Input file $INPUT_FILE not found!"
    exit 1
fi


###-----------------RUN THE WARMUP -----------------------------------

echo "-> Warming up Numba kernels (one-time per node)...."

singularity exec \
    --env NUMBA_CACHE_DIR="$NUMBA_CACHE_DIR" \
    --bind $PWD:/project \
    hamnucret.sif python3 /project/src/modules/AddFreeDNAfe.py

echo "[+] Warm-up done - generic .so files in \$NUMBA_CACHE_DIR"

###-----------------RUN THE COMPUTATION -----------------------------------

echo "-> Launching main worker script....."
singularity exec \
    --env NUMBA_CACHE_DIR="$NUMBA_CACHE_DIR" \
    --env TMPDIR="$TMPDIR" \
    --bind $PWD:/project,"$TMPDIR":"$TMPDIR" \
    hamnucret.sif \
    python3 /project/src/core/calc_freedna_fe.py \
        --infile   "$INPUT_FILE" \
        --outfile  "${OUTPUT_DIR}/${TASK_ID_PADDED}.tsv" \
        --n_workers "$SLURM_NTASKS" \
        --batch_size "$PYTHON_WORKERS_BATCH_SIZE" \
        --dna_method "$DNA_METHOD" \
        --flush_every "$FLUSH_EVERY" 

echo "Free-energy calculation finished - results in ${OUTPUT_DIR}/${TASK_ID_PADDED}.tsv"
